{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************************************\n",
    "# Conversion of Hardware-triggered Data\n",
    "****************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First imports ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T19:30:54.101912Z",
     "start_time": "2021-02-24T19:30:52.403493Z"
    }
   },
   "outputs": [],
   "source": [
    "import cait as ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T20:02:35.221091Z",
     "start_time": "2021-02-20T20:02:35.213604Z"
    }
   },
   "source": [
    ":::{note}\n",
    "**Script Execution**\n",
    "\n",
    "If cait is executed within a Python script rather that with IPython (e.g. Jupyter Notebooks), the main routine has to start with:\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "    \n",
    "The need for the explicit main routine specification is common for multithreading in Python.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T19:30:56.095570Z",
     "start_time": "2021-02-24T19:30:54.104625Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = ai.data.TestData(filepath='test_data/mock_001', duration=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T19:30:57.269160Z",
     "start_time": "2021-02-24T19:30:56.102139Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rdt file written.\n",
      "DataHandler Instance created.\n",
      "#############################################################\n",
      "EVENT NUMBER:  0\n",
      "detector number (starting at 0):  0\n",
      "number of coincident pulses in digitizer module:  0\n",
      "module trigger counter (starts at 0, when TRA or WRITE starts):  1\n",
      "channel trigger delay relative to time stamp [Âµs]:  0\n",
      "absolute time [s] (computer time timeval.tv_sec):  1602879726\n",
      "absolute time [us] (computer time timeval.tv_us):  0\n",
      "Delay of channel trigger to testpulse [us]:  0\n",
      "time stamp of module trigger low word (10 MHz clock, 0 @ START WRITE ):  0\n",
      "time stamp of module trigger high word (10 MHz clock, 0 @ START WRITE ):  6\n",
      "number of qdc events accumulated until digitizer trigger:  0\n",
      "measuring hours (0 @ START WRITE):  0.0016666667070239782\n",
      "accumulated dead time of channel [s] (0 @ START WRITE):  0.0\n",
      "test pulse amplitude (0. for pulses, (0.,10.] for test pulses, >10. for control pulses):  0.10000000149011612\n",
      "DAC output of control program (proportional to heater power):  0.0\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# RDT\n",
    "# ---------------------------------------------------------\n",
    "test_data._generate_rdt_file()\n",
    "dh = ai.DataHandler()\n",
    "dh.checkout_rdt(path_rdt='test_data/mock_001.rdt', read_events=1, verb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T19:30:57.308013Z",
     "start_time": "2021-02-24T19:30:57.270840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con file written.\n",
      "DataHandler Instance created.\n",
      "5 control pulses read from CON file.\n",
      " \tdetector_nmbr,\t \tpulse_height, \ttime_stamp_low, \ttime_stamp_high, \tdead_time, \tmus_since_last_tp\n",
      "1\t0\t\t6.07\t\t30000000\t\t0\t\t\t0.0\t[0]\n",
      "2\t1\t\t4.09\t\t30000000\t\t0\t\t\t0.0\t[0]\n",
      "3\t0\t\t5.56\t\t120000000\t\t0\t\t\t0.0\t[0]\n",
      "4\t1\t\t3.9\t\t120000000\t\t0\t\t\t0.0\t[0]\n",
      "5\t0\t\t6.26\t\t210000000\t\t0\t\t\t0.0\t[0]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# CON\n",
    "# ---------------------------------------------------------\n",
    "test_data._generate_con_file()\n",
    "dh = ai.DataHandler()\n",
    "dh.checkout_con(path_con='test_data/mock_001.con', read_events=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T19:30:57.315035Z",
     "start_time": "2021-02-24T19:30:57.310585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par file written.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# PAR\n",
    "# ---------------------------------------------------------\n",
    "test_data._generate_par_file()\n",
    "# test by looking at the text file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T19:30:58.285776Z",
     "start_time": "2021-02-24T19:30:57.321353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rdt file written.\n",
      "Con file written.\n",
      "Par file written.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# ALL FOR A SECOND FILE\n",
    "# ---------------------------------------------------------\n",
    "test_data.update_filepath(file_path='test_data/mock_002')\n",
    "test_data.generate(start_offset=1.5 * 3600, source='hw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T19:31:09.568092Z",
     "start_time": "2021-02-24T19:30:58.288728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataHandler Instance created.\n",
      "Start converting.\n",
      "READ EVENTS FROM RDT FILE.\n",
      "Total Records in File:  800\n",
      "Event Counts:  399\n",
      "WORKING ON EVENTS WITH TPA = 0.\n",
      "CREATE DATASET WITH EVENTS.\n",
      "CALCULATE MAIN PARAMETERS.\n",
      "WORKING ON EVENTS WITH TPA = -1.\n",
      "CREATE DATASET WITH NOISE.\n",
      "WORKING ON EVENTS WITH TPA > 0.\n",
      "CREATE DATASET WITH TESTPULSES.\n",
      "CALCULATE MP.\n",
      "Hdf5 dataset created in  test_data/\n",
      "Filepath and -name saved.\n",
      "Accessing CON File...\n",
      "200 Control Pulses for channel 0 in file.\n",
      "CON File included.\n",
      "DataHandler Instance created.\n",
      "Start converting.\n",
      "READ EVENTS FROM RDT FILE.\n",
      "Total Records in File:  800\n",
      "Event Counts:  399\n",
      "WORKING ON EVENTS WITH TPA = 0.\n",
      "CREATE DATASET WITH EVENTS.\n",
      "CALCULATE MAIN PARAMETERS.\n",
      "WORKING ON EVENTS WITH TPA = -1.\n",
      "CREATE DATASET WITH NOISE.\n",
      "WORKING ON EVENTS WITH TPA > 0.\n",
      "CREATE DATASET WITH TESTPULSES.\n",
      "CALCULATE MP.\n",
      "Hdf5 dataset created in  test_data/\n",
      "Filepath and -name saved.\n",
      "Accessing CON File...\n",
      "200 Control Pulses for channel 0 in file.\n",
      "CON File included.\n"
     ]
    }
   ],
   "source": [
    "# Conversion from Rdt to HDF5\n",
    "\n",
    "path_data = 'test_data/'\n",
    "file_names = ['mock_001',\n",
    "              'mock_002']\n",
    "\n",
    "for file in file_names:\n",
    "    # --------------------------------------------------\n",
    "    # Convert Rdt to H5\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    dh = ai.DataHandler(run='01',\n",
    "                        module='Test',\n",
    "                        channels=[0, 1],\n",
    "                        record_length=16384,\n",
    "                        sample_frequency=25000)\n",
    "    \n",
    "    dh.convert_dataset(path_rdt=path_data,\n",
    "                       fname=file,\n",
    "                       path_h5=path_data,\n",
    "                       tpa_list=[0, 1, -1],\n",
    "                       calc_mp=True,\n",
    "                       calc_nps=True)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Include con file\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    dh.include_con_file(path_con_file=path_data + file + '.con')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T19:31:09.791548Z",
     "start_time": "2021-02-24T19:31:09.570454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> MERGE GROUP: events.\n",
      "SET: event.\n",
      "creating ...\n",
      "SET: mainpar.\n",
      "creating ...\n",
      "SET: true_ph.\n",
      "SET: true_onset.\n",
      "SET: of_ph.\n",
      "SET: sev_fit_par.\n",
      "SET: sev_fit_rms.\n",
      "SET: hours.\n",
      "creating ...\n",
      "SET: labels.\n",
      "SET: testpulseamplitude.\n",
      "SET: time_s.\n",
      "creating ...\n",
      "SET: time_mus.\n",
      "creating ...\n",
      "SET: pulse_height.\n",
      "--> MERGE GROUP: testpulses.\n",
      "SET: event.\n",
      "creating ...\n",
      "SET: mainpar.\n",
      "creating ...\n",
      "SET: true_ph.\n",
      "SET: true_onset.\n",
      "SET: of_ph.\n",
      "SET: sev_fit_par.\n",
      "SET: sev_fit_rms.\n",
      "SET: hours.\n",
      "creating ...\n",
      "SET: labels.\n",
      "SET: testpulseamplitude.\n",
      "creating ...\n",
      "SET: time_s.\n",
      "creating ...\n",
      "SET: time_mus.\n",
      "creating ...\n",
      "SET: pulse_height.\n",
      "--> MERGE GROUP: noise.\n",
      "SET: event.\n",
      "creating ...\n",
      "SET: mainpar.\n",
      "SET: true_ph.\n",
      "SET: true_onset.\n",
      "SET: of_ph.\n",
      "SET: sev_fit_par.\n",
      "SET: sev_fit_rms.\n",
      "SET: hours.\n",
      "creating ...\n",
      "SET: labels.\n",
      "SET: testpulseamplitude.\n",
      "SET: time_s.\n",
      "creating ...\n",
      "SET: time_mus.\n",
      "creating ...\n",
      "SET: pulse_height.\n",
      "--> MERGE GROUP: controlpulses.\n",
      "SET: event.\n",
      "SET: mainpar.\n",
      "SET: true_ph.\n",
      "SET: true_onset.\n",
      "SET: of_ph.\n",
      "SET: sev_fit_par.\n",
      "SET: sev_fit_rms.\n",
      "SET: hours.\n",
      "creating ...\n",
      "SET: labels.\n",
      "SET: testpulseamplitude.\n",
      "SET: time_s.\n",
      "SET: time_mus.\n",
      "SET: pulse_height.\n",
      "creating ...\n",
      "Deleting test_data/mock_001-P_Ch0-L_Ch1.h5.\n",
      "Deleting test_data/mock_002-P_Ch0-L_Ch1.h5.\n",
      "Merge done.\n"
     ]
    }
   ],
   "source": [
    "# merge the two files\n",
    "\n",
    "ai.data.merge_h5_sets(path_h5_a=path_data + file_names[0] + '-P_Ch0-L_Ch1.h5', \n",
    "                      path_h5_b=path_data + file_names[1] + '-P_Ch0-L_Ch1.h5', \n",
    "                      path_h5_merged=path_data + 'test_001.h5', \n",
    "                      continue_hours=True,\n",
    "                      keep_original_files=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
